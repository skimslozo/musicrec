{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDl0GId2PrL9"
      },
      "source": [
        "**Import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4MUFO7VDPdgo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dhc5Oc3I9VCC"
      },
      "outputs": [],
      "source": [
        "class Connect2Model(nn.Module):\n",
        "\n",
        "    def __init__(self, board_size, action_size, device):\n",
        "\n",
        "        super(Connect2Model, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.size = board_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=self.size, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "\n",
        "        # Two heads on our network\n",
        "        self.action_head = nn.Linear(in_features=64, out_features=self.action_size)\n",
        "        self.value_head = nn.Linear(in_features=64, out_features=1)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        action_logits = self.action_head(x)\n",
        "        value_logit = self.value_head(x)\n",
        "\n",
        "        return F.softmax(action_logits, dim=1), value_logit\n",
        "\n",
        "    def predict(self, board):\n",
        "        board = torch.FloatTensor(board.astype(np.float32)).to(self.device)\n",
        "        board = board.view(1, self.size)\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            pi, v = self.forward(board)\n",
        "\n",
        "        return pi.data.cpu().numpy()[0], v.data.cpu().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fme3ZDd59oPb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, dl_model , model, args, eps):\n",
        "        self.dl_model = dl_model\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "        self.mcts = MCTS_DL(self.dl_model, self.model, self.args)\n",
        "        self.episode_scores = eps\n",
        "\n",
        "    def exceute_episode(self, tmp, plotting, random, greedy):\n",
        "\n",
        "        train_examples = []\n",
        "        state = []\n",
        "\n",
        "        while True:\n",
        "\n",
        "            self.mcts = MCTS_DL(self.dl_model, self.model, self.args)\n",
        "            root = self.mcts.run(state)\n",
        "\n",
        "            action_probs = [0 for _ in range(self.model.n_songs)]\n",
        "            for k, v in root.children.items():\n",
        "                action_probs[k] = v.visit_count\n",
        "\n",
        "            action_probs = action_probs / np.sum(action_probs)\n",
        "            train_examples.append((state, action_probs))\n",
        "\n",
        "            action = root.select_action(temperature=tmp)\n",
        "            state = self.model.get_next_state(state, action)\n",
        "            reward = self.model.get_reward(state)\n",
        "\n",
        "            \n",
        "            if reward is not None:\n",
        "                ret = []\n",
        "                for hist_state, hist_action_probs in train_examples:\n",
        "                    # [Board, actionProbabilities, Reward]\n",
        "                    ret.append((self.model.state_to_input(hist_state), hist_action_probs, reward))\n",
        "                print(hist_state, reward)\n",
        "                if plotting:\n",
        "                  self.episode_scores.append(reward)\n",
        "                  plt.plot(self.episode_scores)\n",
        "                  plt.axhline(y=random, color='b', linestyle='-')\n",
        "                  plt.axhline(y=greedy, color='g', linestyle='-')\n",
        "\n",
        "                  plt.show()\n",
        "\n",
        "                return ret\n",
        "\n",
        "    def learn(self, temperature, random, greedy):\n",
        "        for i in range(1, self.args['numIters'] + 1):\n",
        "\n",
        "            print(\"{}/{}\".format(i, self.args['numIters']))\n",
        "\n",
        "            train_examples = []\n",
        "\n",
        "            for eps in range(self.args['numEps']):\n",
        "                iteration_train_examples = self.exceute_episode(temperature, False, random, greedy)\n",
        "                train_examples.extend(iteration_train_examples)\n",
        "\n",
        "            self.exceute_episode(0, True, random, greedy)\n",
        "            shuffle(train_examples)\n",
        "            self.train(train_examples)\n",
        "            filename = self.args['checkpoint_path']\n",
        "            self.save_checkpoint(folder=\".\", filename=filename)\n",
        "\n",
        "    def train(self, examples):\n",
        "        optimizer = optim.Adam(self.dl_model.parameters(), lr=5e-4)\n",
        "        pi_losses = []\n",
        "        v_losses = []\n",
        "\n",
        "        for epoch in range(self.args['epochs']):\n",
        "          self.dl_model.train()\n",
        "\n",
        "          batch_idx = 0\n",
        "\n",
        "          while batch_idx < int(len(examples) / self.args['batch_size']):\n",
        "            sample_ids = np.random.randint(len(examples), size=self.args['batch_size'])\n",
        "            boards, pis, vs = list(zip(*[examples[i] for i in sample_ids]))\n",
        "            boards = torch.FloatTensor(np.array(boards).astype(np.float64))\n",
        "            target_pis = torch.FloatTensor(np.array(pis))\n",
        "            target_vs = torch.FloatTensor(np.array(vs).astype(np.float64))\n",
        "\n",
        "            # predict\n",
        "            boards = boards.contiguous()\n",
        "            target_pis = target_pis.contiguous()\n",
        "            target_vs = target_vs.contiguous()\n",
        "\n",
        "            # compute output\n",
        "            out_pi, out_v = self.dl_model(boards)\n",
        "            l_pi = self.loss_pi(target_pis, out_pi)\n",
        "            l_v = self.loss_v(target_vs, out_v)\n",
        "            total_loss = l_pi + l_v\n",
        "\n",
        "            pi_losses.append(float(l_pi))\n",
        "            v_losses.append(float(l_v))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_idx += 1\n",
        "    \n",
        "\n",
        "          print()\n",
        "          print(\"Policy Loss\", np.mean(pi_losses))\n",
        "          print(\"Value Loss\", np.mean(v_losses))\n",
        "          # print(\"Examples:\")\n",
        "          # print(out_pi[0].detach())\n",
        "          # print(target_pis[0])\n",
        "          \n",
        "\n",
        "    def loss_pi(self, targets, outputs):\n",
        "        loss = -(targets * torch.log(outputs)).sum(dim=1)\n",
        "        return loss.mean()\n",
        "\n",
        "    def loss_v(self, targets, outputs):\n",
        "        loss = torch.sum((targets-outputs.view(-1))**2)/targets.size()[0]\n",
        "        return loss\n",
        "\n",
        "    def save_checkpoint(self, folder, filename):\n",
        "        if not os.path.exists(folder):\n",
        "            os.mkdir(folder)\n",
        "\n",
        "        filepath = os.path.join(folder, filename)\n",
        "        torch.save({\n",
        "            'state_dict': self.dl_model.state_dict(),\n",
        "        }, filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PLQCEz-NFk6o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import itertools\n",
        "import scipy.spatial.distance as distlib\n",
        "import scipy.stats\n",
        "import random as rand\n",
        "import time\n",
        "\n",
        "class RecommendationSystem:\n",
        "    def __init__(self, dataset_with_bins, n_features, n_bins):\n",
        "        '''\n",
        "        We assume here that the columns of the dataset here are already the binary percentile bins for all features \n",
        "        For sanity check: n_features x n_bins = length(dataset_with_bins)\n",
        "        '''\n",
        "        self.data = dataset_with_bins # assuming this is the whole dataset split that we want to work with\n",
        "        self.data.index = np.arange(np.shape(self.data)[0])\n",
        "        self.n_features = n_features\n",
        "        self.n_bins = n_bins\n",
        "        self.k_s = 10 # user picks 10 songs that they enjoy the most\n",
        "        self.k_t = 10 # for now, just queue the user 10 songs to generate the transition preference model from -- has to be higher than |Action Space| // 2\n",
        "        self.var_param = 100 # parameter that determines the \"variance\" of the user reference distribution that the user song picks are generated from\n",
        "        self.initial_songs = self.gen_user_song_picks() # assuming this is still a pandas df of k_s rows, but only containing the song rows that the user prefers\n",
        "        \n",
        "        # Initialize preferences\n",
        "        self.init_song_preferences()\n",
        "        self.init_transition_preferences()\n",
        "\n",
        "    def init_song_preferences(self):\n",
        "        # Initialize preference array\n",
        "        self.phi_s = (1/((self.k_s + 1) * self.n_bins)) * np.ones((self.n_features * self.n_bins, 1))\n",
        "        tmp = (np.sum(self.initial_songs.values, axis = 0)) * (1/(self.k_s + 1))\n",
        "        self.phi_s = self.phi_s + np.reshape(tmp, (len(tmp), 1))\n",
        "\n",
        "    def theta_t(self, idx_a, idx_b):\n",
        "        '''\n",
        "        Input: indices of songs a and b within the provided dataset (int)\n",
        "\n",
        "        Output: vector theta_t, assuming the feature sequence of 1-i, 1-2, ..., 1-n_bins, 2-1, ..., n_bins-1, n_bins-2, ..., n_bins-n_bins\n",
        "        '''\n",
        "        indices = np.array([], dtype=int)\n",
        "        for i in range(self.n_features):\n",
        "            a_bin_idx = np.where(self.data.loc[idx_a][self.data.columns[i*self.n_bins:(i+1)*self.n_bins]] == 1.0)[0]\n",
        "            b_bin_idx = np.where(self.data.loc[idx_b][self.data.columns[i*self.n_bins:(i+1)*self.n_bins]] == 1.0)[0]\n",
        "            indices = np.append(indices, int(i*(self.n_bins*self.n_bins) + a_bin_idx*self.n_bins + b_bin_idx))\n",
        "        out = np.zeros((self.n_bins * self.n_bins * self.n_features, 1))\n",
        "        out[indices] = 1\n",
        "        return out\n",
        "\n",
        "    def init_transition_preferences(self):\n",
        "        # Initialize user preference vector\n",
        "\n",
        "        # Take the upper-median preference split\n",
        "        self.Rs = np.sum(np.matmul(self.data.values, self.phi_s), axis=1)\n",
        "        self.Mstar = self.data.copy()\n",
        "        self.Mstar['Rs'] = self.Rs\n",
        "        self.Mstar.sort_values('Rs', inplace = True, ascending = False)\n",
        "        self.Mstar = self.Mstar[:np.shape(self.Mstar)[0] // 2]\n",
        "        self.Mstar['old_index'] = self.Mstar.index\n",
        "        self.Mstar.index = np.arange(np.shape(self.Mstar)[0])\n",
        "\n",
        "        # Generate 10th percentile distance of all pairwise distances from M (not M*)\n",
        "        self.diff = distlib.pdist(self.data.values, 'cosine') #taking cosine distance metric between songs\n",
        "        self.delta = np.percentile(self.diff, 10, axis=0)\n",
        "        self.distances = distlib.squareform(self.diff)\n",
        "        np.fill_diagonal(self.distances, np.inf)\n",
        "\n",
        "        # Generate a representative subset of M*\n",
        "        self.representatives = self.delta_medoids(self.Mstar, self.delta)\n",
        "        if self.k_t > len(self.representatives):\n",
        "            print(\"[WARNING] k_t parameter too large for generated representative subset. Consider using a larger dataset or reducing k_t value\")\n",
        "            print(\"Setting k_t =\", len(self.representatives), \"to match the generated number of representatives through delta-medoids\")\n",
        "            self.k_t = len(self.representatives)\n",
        "        song_prev = np.random.choice(self.representatives)\n",
        "        self.representatives = np.delete(self.representatives, np.argwhere(self.representatives == song_prev))\n",
        "        #TODO: constraint k_t between length of representatives, give warning message\n",
        "\n",
        "        self.phi_t = (1/(self.k_t * self.n_bins*self.n_bins)) * np.ones((self.n_features * self.n_bins * self.n_bins, 1))\n",
        "        \n",
        "        for i in range(self.k_t-1):\n",
        "            next_song, theta = self.pick_next_song(song_prev, self.user_ref_samples_t[:, i])\n",
        "            self.phi_t += (1/(self.k_t)) * theta\n",
        "            song_prev = next_song\n",
        "\n",
        "    def pick_next_song(self, previous_song, reference):\n",
        "        min_dist = 1e06\n",
        "        for song in self.representatives:\n",
        "            theta_current = self.theta_t(previous_song, song)\n",
        "            dist = distlib.cosine(theta_current, reference)\n",
        "            if dist < min_dist:\n",
        "                min_theta = theta_current\n",
        "                min_song = song\n",
        "                min_dist = dist\n",
        "\n",
        "        self.representatives = np.delete(self.representatives, np.argwhere(self.representatives == min_song))\n",
        "        return min_song, min_theta\n",
        "\n",
        "    def one_shot_delta(self, data, delta, clusters):\n",
        "        # Remember to change the distance metric in case we change delta distance definition\n",
        "        distances = distlib.pdist(data[data.columns[:-2]], 'cosine')\n",
        "        distances = distlib.squareform(distances)\n",
        "        np.fill_diagonal(distances, np.inf) # Need to populate the diagonals with inf since we look for the smallest off-diagonal value afterwards\n",
        "        for index, row in data.iterrows():\n",
        "            dist = 1e6\n",
        "            representatives = np.array(list(clusters.keys()))\n",
        "            representatives.dtype = 'int64'\n",
        "\n",
        "            if len(representatives) > 0:\n",
        "              # rep = np.where(distances[:, index] == np.min(distances[:, index][representatives]))[0]\n",
        "              rep = np.intersect1d(np.where(distances[:, index] == np.min(distances[:, index][representatives]))[0], representatives) # Take the intersection to make sure we select the correct index belonging to the set of representatives\n",
        "              if len(rep) > 1:\n",
        "                  rep = rep[0]\n",
        "              else:\n",
        "                  rep = int(rep)\n",
        "              dist = distances[rep, index]\n",
        "\n",
        "            if dist <= delta:\n",
        "                clusters[rep] = np.append(clusters[rep], index)\n",
        "            else: \n",
        "                rep = index\n",
        "                clusters[rep] = np.array([rep])\n",
        "\n",
        "        out = clusters.keys()\n",
        "        return clusters\n",
        "\n",
        "    def delta_medoids(self, data, delta):\n",
        "        distances = distlib.pdist(data[data.columns[:-2]], 'cosine')\n",
        "        distances = distlib.squareform(distances)\n",
        "        np.fill_diagonal(distances, 0)\n",
        "        exit_loop = False\n",
        "        i = 0\n",
        "        clusters = {}\n",
        "        while not exit_loop:\n",
        "            i +=1\n",
        "            clusters = self.one_shot_delta(data, delta, clusters)\n",
        "            if 1 != i:\n",
        "                representatives_prev = representatives\n",
        "            else:\n",
        "                representatives_prev = np.array([], dtype = 'int32')\n",
        "            representatives = np.array([], dtype = 'int32')\n",
        "            for cluster in clusters.items():\n",
        "                cluster = cluster[1]\n",
        "                cluster_dists = distlib.pdist(data.loc[cluster], 'cosine')\n",
        "                cluster_dists = distlib.squareform(cluster_dists)\n",
        "                argmin = np.argmin(np.sum(cluster_dists, axis=0))\n",
        "                representatives = np.append(representatives, cluster[argmin])\n",
        "            if np.array_equal(np.sort(representatives), np.sort(representatives_prev)):\n",
        "                exit_loop = True\n",
        "        # Convert back to indices of the original data array\n",
        "        representatives = data['old_index'][np.in1d(data.index, representatives)].values\n",
        "        return representatives\n",
        "\n",
        "    def gen_user_song_picks(self):\n",
        "        \"\"\"\n",
        "        Returns a subset of the dataframe of k_s songs closest to the random samples generated from the user preference distribution, simulating picked user reference\n",
        "        The user reference distribution is generated here and can be accessed through self.user_ref\n",
        "        \"\"\"\n",
        "        self.user_ref_s, self.user_ref_samples_s, self.user_ref_t, self.user_ref_samples_t  = self.gen_user_ref()\n",
        "        sample_index = np.arange(np.shape(self.data)[0], np.shape(self.data)[0] + self.k_s, dtype='int32')\n",
        "        to_append = pd.DataFrame(np.transpose(self.user_ref_samples_s), index = sample_index)\n",
        "        sample = self.data.copy().append(to_append)\n",
        "        dists_with_samples = distlib.pdist(sample, metric='cosine')\n",
        "        dists_with_samples = distlib.squareform(dists_with_samples)\n",
        "        np.fill_diagonal(dists_with_samples, np.inf)\n",
        "        user_selected_songs = np.array([], dtype='int32')\n",
        "\n",
        "        for i in sample_index:\n",
        "            min_ind = np.argmin(dists_with_samples[:sample_index[0], i])\n",
        "            user_selected_songs = np.append(user_selected_songs, min_ind)\n",
        "            dists_with_samples[min_ind, :] = np.inf #Do not allow to pick this row anymore\n",
        "        return self.data.loc[user_selected_songs]\n",
        "        \n",
        "\n",
        "    def gen_user_ref(self):\n",
        "        '''\n",
        "        Generates a random \"ground-truth\" user song and transitions preference distributions over features (kind of\n",
        "        like a ground-truth phi_s and phi_t), as well as k_s for songs (and k_t, for transitions, respectively) samples from it, that are later used to \n",
        "        simulate user song preferences and transition preferences that the user preference vectors phi_s and phi_t are learned from\n",
        "\n",
        "        Input: var_param: a parameter that alters the variance of the distribution over each feature of the ground truth user preference vectors, int\n",
        "\n",
        "        Output: - user_reference_s (numpy array, n_bins x n_features, 1): ground-truth user song preference distribution over each feature\n",
        "                - user_samples_s (numpy array, n_bins x n_features, k_s): k_s samples of the \"ground truth phi_s\", used to select initial, user-preferred songs\n",
        "                - user_reference_t (numpy array, n_bins*n_bins x n_features, 1): ground-truth user transition preference distribution over each feature\n",
        "                - user_samples_t (numpy array, n_bins*n_bins x n_features, k_t): k_s samples of the \"ground truth phi_t\", used to select songs that the user preference phi_t will be estimated from \n",
        "        '''\n",
        "    \n",
        "        user_reference_s = np.array([])\n",
        "        user_reference_t = np.array([])\n",
        "\n",
        "        user_samples_s = np.zeros((self.n_features * self.n_bins, self.k_s))\n",
        "        user_samples_t = np.zeros((self.n_features * self.n_bins * self.n_bins, self.k_t))\n",
        "\n",
        "        for i in range(self.n_features):\n",
        "            vec_s = np.random.randint(1, self.var_param, (self.n_bins, ))\n",
        "            vec_s = vec_s/np.sum(vec_s)\n",
        "            user_reference_s = np.append(user_reference_s, vec_s)\n",
        "            sample_bins_s = np.array(rand.choices(np.arange(self.n_bins, dtype='int32'), vec_s, k = self.k_s))\n",
        "            user_samples_s[i*self.n_bins + sample_bins_s, np.arange(self.k_s, dtype='int32')] = 1\n",
        "            \n",
        "            vec_t = np.random.randint(1, self.var_param, (self.n_bins * self.n_bins, ))\n",
        "            vec_t = vec_t/np.sum(vec_t)\n",
        "            user_reference_t = np.append(user_reference_t, vec_t)\n",
        "            sample_bins_t = np.array(rand.choices(np.arange(self.n_bins * self.n_bins, dtype='int32'), vec_t, k = self.k_t))\n",
        "            user_samples_t[i*self.n_bins*self.n_bins + sample_bins_t, np.arange(self.k_t, dtype='int32')] = 1\n",
        "\n",
        "        return user_reference_s, user_samples_s, user_reference_t, user_samples_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SND1-OJ3D4hI"
      },
      "outputs": [],
      "source": [
        "def ucb_score(parent, child):\n",
        "    \"\"\"\n",
        "    The score for an action that would transition between the parent and child.\n",
        "    \"\"\"\n",
        "    if child.prior < 0.0001:\n",
        "      return -100000000\n",
        "    prior_score = child.prior * math.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
        "    if child.visit_count > 0:\n",
        "        # The value of the child is from the perspective of the opposing player\n",
        "        value_score = child.value()\n",
        "    else:\n",
        "        value_score = 100000\n",
        "\n",
        "    return value_score + prior_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0DKpyChhthYt"
      },
      "outputs": [],
      "source": [
        "class MDP:\n",
        "    def __init__(self, file_name, playlist_length):\n",
        "\n",
        "        df = pd.read_csv(file_name, index_col=None)\n",
        "\n",
        "        self.features = ['duration', 'key_confidence', 'end_of_fade_in', 'mode_confidence', 'start_of_fade_out', 'tempo',\n",
        "                    'artist_hotttnesss', 'song_hotttnesss']\n",
        "\n",
        "        for feature in self.features:\n",
        "          filter = df[feature] > 0\n",
        "          df = df[filter]\n",
        "        \n",
        "        self.filtered_df = df[self.features]\n",
        "        self.filtered_df.dropna(inplace=True)\n",
        "        self.filtered_df = self.filtered_df.head(100)\n",
        "        self.filtered_df = self.filtered_df.reset_index(drop=True)\n",
        "        self.n_rows = len(self.filtered_df.index)\n",
        "        self.n_songs = self.n_rows\n",
        "        print(self.n_songs)\n",
        "        self.n_bins = 10\n",
        "        self.n_features = len(self.features)\n",
        "        self.id_song_to_vec = dict()\n",
        "        self.songs = set()        \n",
        "        self.song_id_to_song_row = []\n",
        "        self.song_priors = []\n",
        "        self.playlist_length = playlist_length\n",
        "        self.id_song_to_features = dict()\n",
        "\n",
        "        song_id = 0\n",
        "      \n",
        "        for song, row in self.filtered_df.iterrows():\n",
        "            self.id_song_to_vec[song_id] = np.zeros(80)\n",
        "            self.id_song_to_features[song_id] = np.zeros(self.n_features)\n",
        "\n",
        "            for f in range(self.n_features):\n",
        "              feature = self.features[f]\n",
        "              self.id_song_to_features[song_id][f] = row[feature]\n",
        "\n",
        "            self.songs.add(song_id)\n",
        "            self.song_id_to_song_row.append(row)\n",
        "            self.song_priors.append(1)\n",
        "            song_id += 1\n",
        "\n",
        "        print(self.id_song_to_features)\n",
        "\n",
        "\n",
        "        self.songs_list = [i for i in range(self.n_songs)]\n",
        "\n",
        "        for f in range(self.n_features):\n",
        "\n",
        "            feature = self.features[f]\n",
        "            sorted_df = self.filtered_df.sort_values(by=[feature])\n",
        "            i = 0\n",
        "            for idx, row in sorted_df.iterrows():\n",
        "                bin = i * self.n_bins // self.n_rows\n",
        "                self.id_song_to_vec[idx][f * 10 + bin] = 1\n",
        "                i += 1\n",
        "\n",
        "\n",
        "        self.df_input = pd.DataFrame.from_dict(self.id_song_to_vec, orient='index')\n",
        "        # Select songs that the user prefers (randomly selecting 5 for now, change later)\n",
        "        rs = RecommendationSystem(self.df_input, self.n_features, self.n_bins)\n",
        "        self.phi_s = rs.phi_s.reshape(80)\n",
        "        self.phi_t = rs.phi_t.reshape(800)\n",
        "\n",
        "        self.transition_reward = np.zeros((self.n_songs, self.n_songs))\n",
        "        self.song_reward = np.zeros(self.n_songs)\n",
        "        for i in range(self.n_songs):\n",
        "          self.song_reward[i] = np.dot(self.phi_s, self.theta_s(i))\n",
        "          for j in range(self.n_songs):\n",
        "            self.transition_reward[i,j] = np.dot(self.phi_t, self.get_theta_t(i, j))\n",
        "\n",
        "\n",
        "    def get_next_state(self, state, action):\n",
        "      return state + [action]\n",
        "      \n",
        "    def get_valid_actions(self, state):\n",
        "        # All actions are invalid by default\n",
        "        valid_actions = [0] * self.n_songs\n",
        "\n",
        "        for song in range(self.n_songs):\n",
        "            if song not in state:\n",
        "                valid_actions[song] = 1\n",
        "\n",
        "        return valid_actions\n",
        "\n",
        "    def state_to_input(self, state):\n",
        "      input = np.ones(self.playlist_length*self.n_features*10)*-1\n",
        "      for i in range(len(state)):\n",
        "        song = state[i]\n",
        "        input[i*self.n_features*10:(i+1)*self.n_features*10] = self.id_song_to_vec[song]\n",
        "      return input\n",
        "\n",
        "    def get_reward(self, final_state):\n",
        "      if len(final_state) < self.playlist_length:\n",
        "        return None\n",
        "      elif len(final_state) == self.playlist_length:\n",
        "        state = []\n",
        "        trajectory_states = [state]\n",
        "        trajectory_actions = []\n",
        "        for song in final_state:\n",
        "          state = self.get_next_state(state, song)\n",
        "          trajectory_states.append(state)\n",
        "          trajectory_actions.append(song)\n",
        "          \n",
        "        return self.payoff_trajectory(trajectory_states, trajectory_actions)\n",
        "      else:\n",
        "        print(\"Error: length > self.playlist_length\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    def get_theta_t(self, s1, s2):\n",
        "        theta_t = np.zeros(800)\n",
        "        for f in range(len(self.features)):\n",
        "            for i in range(10):\n",
        "                for j in range(10):\n",
        "                    if self.id_song_to_vec[s1][f*10 + i] == 1 and  self.id_song_to_vec[s2][f*10 + j]:\n",
        "                        theta_t[f*100 + i*10 + j] = 1\n",
        "        return  theta_t\n",
        "\n",
        "    def theta_s(self, s):\n",
        "        return self.id_song_to_vec[s]\n",
        "\n",
        "    def R(self, s, a):\n",
        "        Rs = self.song_reward[a]\n",
        "        Rt = 0\n",
        "        for i in range(len(s)):\n",
        "            song_past = s[len(s)-i-1]\n",
        "            Rt += 1/((i+1)**(0.1)) * self.transition_reward[song_past,a]\n",
        "        return Rs + Rt\n",
        "\n",
        "\n",
        "    def payoff_trajectory(self, trajectory_states, trajectory_actions):\n",
        "      payoff = 0\n",
        "\n",
        "      for t in range(len(trajectory_actions)):\n",
        "        payoff +=  self.R(trajectory_states[t], trajectory_actions[t])\n",
        "      return payoff\n",
        "\n",
        "    def MC_value(self, s):\n",
        "      count = 0\n",
        "      sum_values = 0\n",
        "      state = s\n",
        "      # Past episodes\n",
        "      episode_states = [[]]\n",
        "      episode_actions = []\n",
        "\n",
        "      for i in range(model.playlist_length):\n",
        "        if i < len(s):\n",
        "          state = s[:i+1]\n",
        "          action = s[i]\n",
        "        else:\n",
        "          action_probs = list(model.song_priors)\n",
        "          for song_id in range(model.n_songs):\n",
        "            if song_id in state:\n",
        "              action_probs[song_id] = 0\n",
        "\n",
        "          action_probs = np.array(action_probs)/np.sum(np.array(action_probs))\n",
        "          action = np.random.choice(model.songs_list, 1, p=action_probs)[0]\n",
        "          state = episode_states[-1] + [action]\n",
        "        episode_states.append(state)\n",
        "        episode_actions.append(action)\n",
        "\n",
        "      # print(\"MC estimate:\", s, episode_states, episode_actions)\n",
        "          \n",
        "      # Set MC \n",
        "      payoff = self.payoff_trajectory(episode_states, episode_actions)\n",
        "      \n",
        "      return payoff\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, prior):\n",
        "        self.visit_count = 0\n",
        "        self.prior = prior\n",
        "        self.value_sum = 0\n",
        "        self.children = {}\n",
        "        self.state = None\n",
        "\n",
        "    def expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def value(self):\n",
        "        if self.visit_count == 0:\n",
        "            return 0\n",
        "        return self.value_sum / self.visit_count\n",
        "\n",
        "    def select_action(self, temperature):\n",
        "        \"\"\"\n",
        "        Select action according to the visit count distribution and the temperature.\n",
        "        \"\"\"\n",
        "        visit_counts = np.array([child.visit_count for child in self.children.values()])\n",
        "        actions = [action for action in self.children.keys()]\n",
        "        if temperature == 0:\n",
        "            action = actions[np.argmax(visit_counts)]\n",
        "        elif temperature == float(\"inf\"):\n",
        "            action = np.random.choice(actions)\n",
        "        else:\n",
        "            # See paper appendix Data Generation\n",
        "            visit_count_distribution = visit_counts ** (1 / temperature)\n",
        "            visit_count_distribution = visit_count_distribution / sum(visit_count_distribution)\n",
        "            action = np.random.choice(actions, p=visit_count_distribution)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def select_child(self):\n",
        "        \"\"\"\n",
        "        Select the child with the highest UCB score.\n",
        "        \"\"\"\n",
        "        best_score = -np.inf\n",
        "        best_action = -1\n",
        "        best_child = None\n",
        "\n",
        "        for action, child in self.children.items():\n",
        "            score = ucb_score(self, child)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_action = action\n",
        "                best_child = child\n",
        "\n",
        "        return best_action, best_child\n",
        "\n",
        "    def expand(self, state, action_probs):\n",
        "        \"\"\" \n",
        "        We expand a node and keep track of the prior policy probability given by neural network\n",
        "        \"\"\"\n",
        "        self.state = state\n",
        "        for song_id in range(len(action_probs)):\n",
        "              self.children[song_id] = Node(action_probs[song_id])\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Debugger pretty print node info\n",
        "        \"\"\"\n",
        "        prior = \"{0:.2f}\".format(self.prior)\n",
        "        return \"{} Prior: {} Count: {} Value: {}\".format(self.state.__str__(), prior, self.visit_count, self.value())\n",
        "\n",
        "\n",
        "# print(MDP.id_song_to_vec[1])\n",
        "# print(MDP.id_song_to_vec[20])\n",
        "\n",
        "# print(MDP.theta_t(1,20))\n",
        "# print(MDP.R([1], 20))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "{0: array([252.05506   ,   0.777     ,   2.049     ,   0.688     ,\n",
            "       236.635     ,  87.002     ,   0.39403189,   0.54289874]), 1: array([156.55138   ,   0.808     ,   0.258     ,   0.355     ,\n",
            "       148.66      , 150.778     ,   0.35699211,   0.29987749]), 2: array([318.45832   ,   0.764     ,   0.502     ,   0.627     ,\n",
            "       306.265     ,  67.567     ,   0.40698473,   0.46348966]), 3: array([2.73188120e+02, 2.26000000e-01, 3.40000000e-01, 3.50000000e-01,\n",
            "       2.59738000e+02, 1.11007000e+02, 3.73679186e-01, 4.49940204e-01]), 4: array([2.62268930e+02, 3.80000000e-02, 1.94000000e-01, 3.37000000e-01,\n",
            "       2.59419000e+02, 1.22332000e+02, 4.10228511e-01, 2.12045405e-01]), 5: array([216.47628   ,   0.564     ,   2.032     ,   0.655     ,\n",
            "       208.062     ,  99.214     ,   0.44673297,   0.270776  ]), 6: array([217.57342   ,   0.77      ,   0.514     ,   0.417     ,\n",
            "       214.309     ,  88.423     ,   0.5633669 ,   0.71731903]), 7: array([3.53775870e+02, 2.16000000e-01, 3.51000000e-01, 4.25000000e-01,\n",
            "       3.43255000e+02, 1.67850000e+02, 2.90242070e-01, 2.90303599e-01]), 8: array([2.10938320e+02, 4.46000000e-01, 2.47000000e-01, 1.67000000e-01,\n",
            "       2.10938000e+02, 2.07903000e+02, 4.17882034e-01, 2.24820030e-01]), 9: array([1.55193020e+02, 5.10000000e-01, 8.40000000e-02, 5.86000000e-01,\n",
            "       1.46332000e+02, 6.71180000e+01, 3.46357522e-01, 4.60484845e-01]), 10: array([2.28440360e+02, 7.46000000e-01, 7.30000000e-02, 2.95000000e-01,\n",
            "       2.19899000e+02, 1.12945000e+02, 3.81921210e-01, 5.29468533e-01]), 11: array([282.93179   ,   0.828     ,   4.807     ,   0.667     ,\n",
            "       279.406     , 162.002     ,   0.4851047 ,   0.73585316]), 12: array([152.68526   ,   0.453     ,   0.473     ,   0.346     ,\n",
            "       146.727     ,  89.747     ,   0.30010724,   0.43016064]), 13: array([3.49988120e+02, 4.37000000e-01, 3.57000000e-01, 3.47000000e-01,\n",
            "       3.31372000e+02, 1.09398000e+02, 5.61394075e-01, 6.16251219e-01]), 14: array([2.50984040e+02, 3.22000000e-01, 1.65000000e-01, 5.39000000e-01,\n",
            "       2.38039000e+02, 1.35598000e+02, 1.44684661e-01, 4.73346541e-01]), 15: array([194.29832   ,   0.562     ,   0.879     ,   0.482     ,\n",
            "       185.539     , 121.421     ,   0.28974077,   0.28848164]), 16: array([194.5073    ,   0.72      ,   0.218     ,   0.543     ,\n",
            "       191.292     , 140.025     ,   0.40847059,   0.33470655]), 17: array([5.31173420e+02, 2.35000000e-01, 2.17700000e+00, 9.80000000e-02,\n",
            "       5.27552000e+02, 1.26017000e+02, 4.00220682e-01, 3.04169503e-01]), 18: array([195.10812   ,   0.449     ,   0.349     ,   0.568     ,\n",
            "       189.742     , 164.452     ,   0.47057712,   0.24686509]), 19: array([3.56518730e+02, 5.80000000e-02, 6.70000000e-02, 4.46000000e-01,\n",
            "       3.44335000e+02, 8.21700000e+01, 4.27148607e-01, 6.60560037e-01]), 20: array([2.98056690e+02, 6.24000000e-01, 2.09000000e+00, 7.25000000e-01,\n",
            "       2.98057000e+02, 9.30520000e+01, 4.13624754e-01, 2.12045405e-01]), 21: array([329.40363   ,   0.53      ,   6.269     ,   0.438     ,\n",
            "       299.148     , 144.005     ,   0.41069158,   0.3759843 ]), 22: array([168.33261   ,   0.238     ,   0.177     ,   0.327     ,\n",
            "       163.654     , 141.063     ,   0.46111641,   0.56858892]), 23: array([179.59138   ,   0.794     ,   3.75      ,   0.682     ,\n",
            "       165.523     , 168.024     ,   0.44792154,   0.25383474]), 24: array([250.74893   ,   0.797     ,   0.636     ,   0.607     ,\n",
            "       250.749     , 107.989     ,   0.55775567,   0.41373984]), 25: array([161.95873   ,   0.415     ,   2.38      ,   0.498     ,\n",
            "       155.202     , 159.434     ,   0.32036692,   0.39439486]), 26: array([1.82517100e+02, 8.27000000e-01, 4.03000000e-01, 7.79000000e-01,\n",
            "       1.72362000e+02, 2.41715000e+02, 3.95822646e-01, 2.12045405e-01]), 27: array([1.95499950e+02, 4.80000000e-02, 2.31000000e-01, 3.18000000e-01,\n",
            "       1.88308000e+02, 8.59160000e+01, 4.83035298e-01, 6.33197379e-01]), 28: array([6.78895870e+02, 8.85000000e-01, 3.08800000e+00, 8.35000000e-01,\n",
            "       6.61438000e+02, 8.00820000e+01, 5.07956992e-01, 6.02435712e-01]), 29: array([204.61669   ,   0.594     ,   0.222     ,   0.409     ,\n",
            "       201.95      ,  89.966     ,   0.47546513,   0.48732668]), 30: array([174.70649   ,   0.617     ,   0.289     ,   0.483     ,\n",
            "       171.265     , 136.494     ,   0.37831542,   0.40723301]), 31: array([285.70077   ,   0.726     ,   0.996     ,   0.543     ,\n",
            "       283.591     ,  82.679     ,   0.51148628,   0.38647729]), 32: array([4.71744850e+02, 1.62000000e-01, 6.65800000e+00, 1.68000000e-01,\n",
            "       4.26864000e+02, 1.39019000e+02, 3.91005786e-01, 4.45454525e-01]), 33: array([6.17534240e+02, 9.90000000e-02, 3.92000000e-01, 4.56000000e-01,\n",
            "       5.53488000e+02, 1.24824000e+02, 3.31566220e-01, 3.52232225e-01]), 34: array([5.14637910e+02, 5.08000000e-01, 1.83000000e-01, 4.77000000e-01,\n",
            "       5.05818000e+02, 1.36923000e+02, 3.77787709e-01, 5.54371243e-01]), 35: array([175.59465   ,   0.739     ,   0.316     ,   0.705     ,\n",
            "       170.162     , 122.722     ,   0.39582265,   0.3759843 ]), 36: array([3.19059140e+02, 1.00000000e+00, 2.07200000e+00, 7.58000000e-01,\n",
            "       3.13510000e+02, 1.51260000e+02, 3.21253460e-01, 2.66955186e-01]), 37: array([5.19392200e+02, 1.82000000e-01, 3.00700000e+00, 6.17000000e-01,\n",
            "       5.13916000e+02, 1.28069000e+02, 4.50595416e-01, 7.14674160e-01]), 38: array([136.88118   ,   0.384     ,   0.39      ,   0.384     ,\n",
            "       131.146     , 147.355     ,   0.3431335 ,   0.26586105]), 39: array([270.47138   ,   0.448     ,   0.321     ,   0.48      ,\n",
            "       253.841     , 119.758     ,   0.56634958,   0.78648928]), 40: array([305.78893   ,   0.412     ,   6.676     ,   0.604     ,\n",
            "       293.03      , 140.087     ,   0.51169342,   0.50748984]), 41: array([178.88608   ,   0.604     ,   3.477     ,   0.705     ,\n",
            "       164.171     , 155.655     ,   0.41835668,   0.36037058]), 42: array([257.61914   ,   0.903     ,   0.403     ,   0.534     ,\n",
            "       245.557     , 124.38      ,   0.40851443,   0.55884968]), 43: array([226.06322   ,   0.727     ,   0.363     ,   0.525     ,\n",
            "       214.756     ,  90.49      ,   0.44632588,   0.48711219]), 44: array([2.21596280e+02, 6.45000000e-01, 1.92000000e-01, 6.51000000e-01,\n",
            "       2.17368000e+02, 9.73180000e+01, 5.57766778e-01, 6.28217965e-01]), 45: array([3.50197100e+02, 1.78000000e-01, 9.80000000e-02, 2.23000000e-01,\n",
            "       3.50197000e+02, 1.20084000e+02, 4.80348130e-01, 2.66955186e-01]), 46: array([220.57751   ,   0.37      ,   0.88      ,   0.356     ,\n",
            "       210.129     , 132.971     ,   0.3341173 ,   0.34092276]), 47: array([179.51302   ,   0.34      ,   0.399     ,   0.545     ,\n",
            "       165.622     , 101.151     ,   0.23525448,   0.29987749]), 48: array([1.81393830e+02, 2.60000000e-02, 2.65900000e+00, 1.84000000e-01,\n",
            "       1.75647000e+02, 1.21991000e+02, 5.17721371e-01, 2.15080319e-01]), 49: array([3.33922810e+02, 4.50000000e-02, 2.63000000e-01, 3.93000000e-01,\n",
            "       3.28574000e+02, 9.42000000e+01, 3.65146671e-01, 5.69275651e-01]), 50: array([3.01975060e+02, 7.84000000e-01, 9.60000000e-02, 6.49000000e-01,\n",
            "       2.93320000e+02, 9.98120000e+01, 3.43719417e-01, 3.04169503e-01]), 51: array([2.23790570e+02, 3.10000000e-02, 1.13000000e-01, 2.88000000e-01,\n",
            "       2.18244000e+02, 1.49081000e+02, 3.38273866e-01, 4.32388738e-01]), 52: array([258.42893   ,   0.534     ,   0.328     ,   0.557     ,\n",
            "       252.558     , 132.979     ,   0.46398918,   0.79393522]), 53: array([220.76036   ,   0.811     ,   0.467     ,   0.779     ,\n",
            "       210.454     , 103.253     ,   0.29498662,   0.2450533 ]), 54: array([7.82624000e+01, 1.13000000e-01, 6.70000000e-02, 3.28000000e-01,\n",
            "       7.51460000e+01, 1.18745000e+02, 4.64547023e-01, 4.07901717e-01]), 55: array([213.78567   ,   0.402     ,   0.56      ,   0.436     ,\n",
            "       198.258     , 134.899     ,   0.41172715,   0.50375206]), 56: array([3.69214240e+02, 9.02000000e-01, 3.97000000e-01, 8.32000000e-01,\n",
            "       3.47301000e+02, 1.37513000e+02, 4.20937755e-01, 2.65861049e-01]), 57: array([3.02340770e+02, 2.32000000e-01, 2.00000000e-01, 2.07000000e-01,\n",
            "       3.00031000e+02, 1.18231000e+02, 3.19266430e-01, 2.66955186e-01]), 58: array([3.13416690e+02, 5.01000000e-01, 8.58600000e+00, 6.62000000e-01,\n",
            "       2.96681000e+02, 1.20068000e+02, 4.68011964e-01, 2.85915251e-01]), 59: array([189.54404   ,   0.501     ,   7.755     ,   0.525     ,\n",
            "       175.589     ,  65.13      ,   0.42648933,   0.57172901]), 60: array([135.99302   ,   0.196     ,   0.26      ,   0.238     ,\n",
            "       132.122     , 148.874     ,   0.41902418,   0.30168176]), 61: array([118.33424   ,   0.871     ,   0.194     ,   0.939     ,\n",
            "       112.106     ,  92.492     ,   0.22416451,   0.1922688 ]), 62: array([2.46752200e+02, 1.96000000e-01, 2.18000000e-01, 5.37000000e-01,\n",
            "       2.30168000e+02, 8.10340000e+01, 4.32260368e-01, 3.40922756e-01]), 63: array([2.22197100e+02, 5.66000000e-01, 9.60000000e-02, 7.16000000e-01,\n",
            "       2.08149000e+02, 9.59870000e+01, 6.75191947e-01, 7.22524431e-01]), 64: array([189.12608   ,   0.24      ,   0.258     ,   0.323     ,\n",
            "       180.535     ,  85.202     ,   0.57736412,   0.60918886]), 65: array([293.3024    ,   0.353     ,   0.311     ,   0.473     ,\n",
            "       283.034     ,  91.276     ,   0.40051795,   0.36037058]), 66: array([2.29485260e+02, 1.89000000e-01, 7.60000000e-02, 3.30000000e-01,\n",
            "       2.26186000e+02, 8.46730000e+01, 4.51890700e-01, 5.44750913e-01]), 67: array([2.48894240e+02, 6.75000000e-01, 1.60000000e-01, 5.79000000e-01,\n",
            "       2.36565000e+02, 1.07480000e+02, 3.62116006e-01, 2.96784744e-01]), 68: array([228.46649   ,   0.506     ,   0.311     ,   0.558     ,\n",
            "       216.311     , 120.011     ,   0.64298222,   0.2396291 ]), 69: array([1.55166890e+02, 4.63000000e-01, 1.14000000e-01, 3.89000000e-01,\n",
            "       1.46442000e+02, 1.68064000e+02, 4.71309955e-01, 6.97387514e-01]), 70: array([2.55346490e+02, 1.00000000e+00, 2.12000000e-01, 6.51000000e-01,\n",
            "       2.49353000e+02, 9.06120000e+01, 3.43269629e-01, 4.19125893e-01]), 71: array([2.52473020e+02, 6.32000000e-01, 1.71000000e-01, 6.00000000e-01,\n",
            "       2.29042000e+02, 9.26240000e+01, 4.82573874e-01, 5.76761565e-01]), 72: array([244.47955   ,   0.684     ,   0.351     ,   0.47      ,\n",
            "       231.207     , 166.087     ,   0.49929821,   0.62092723]), 73: array([2.59865670e+02, 3.25000000e-01, 1.83000000e-01, 3.33000000e-01,\n",
            "       2.45429000e+02, 1.13016000e+02, 3.49207249e-01, 4.33861382e-01]), 74: array([161.95873   ,   0.587     ,   0.967     ,   0.589     ,\n",
            "       155.051     ,  76.999     ,   0.35689801,   0.270776  ]), 75: array([3.10517100e+02, 5.40000000e-02, 8.00000000e-02, 3.94000000e-01,\n",
            "       3.06178000e+02, 1.56356000e+02, 4.08246219e-01, 6.51223913e-01]), 76: array([9.31522000e+01, 2.90000000e-02, 4.66000000e-01, 3.05000000e-01,\n",
            "       9.31520000e+01, 9.52700000e+01, 5.66446463e-01, 7.29096934e-01]), 77: array([1.97224040e+02, 4.04000000e-01, 7.80000000e-02, 4.90000000e-01,\n",
            "       1.88697000e+02, 8.33640000e+01, 4.05143447e-01, 3.67273416e-01]), 78: array([146.25914   ,   0.752     ,   0.189     ,   0.624     ,\n",
            "       139.865     , 140.836     ,   0.34848962,   0.37879238]), 79: array([152.97261   ,   0.652     ,   0.328     ,   0.584     ,\n",
            "       149.339     , 140.703     ,   0.33771911,   0.35528554]), 80: array([218.87955   ,   0.791     ,   0.228     ,   0.72      ,\n",
            "       211.946     , 132.982     ,   0.38599833,   0.62119568]), 81: array([146.36363   ,   0.747     ,   0.299     ,   0.682     ,\n",
            "       136.707     , 156.664     ,   0.44724581,   0.47405483]), 82: array([211.77424   ,   0.813     ,   2.473     ,   0.8       ,\n",
            "       201.665     , 150.947     ,   0.3468274 ,   0.34092276]), 83: array([229.35465   ,   0.324     ,   2.891     ,   0.412     ,\n",
            "       217.96      , 122.638     ,   0.41339391,   0.46048484]), 84: array([184.81587   ,   0.599     ,   0.218     ,   0.611     ,\n",
            "       178.631     , 165.059     ,   0.40433372,   0.36727342]), 85: array([348.02893   ,   0.585     ,   3.947     ,   0.578     ,\n",
            "       310.393     ,  90.996     ,   0.41478066,   0.38293509]), 86: array([257.69751   ,   0.519     ,   0.346     ,   0.605     ,\n",
            "       246.097     , 128.896     ,   0.45873081,   0.544514  ]), 87: array([2.93041180e+02, 9.30000000e-02, 2.47300000e+00, 3.99000000e-01,\n",
            "       2.81554000e+02, 1.14581000e+02, 3.83266462e-01, 2.65861049e-01]), 88: array([2.71359550e+02, 5.37000000e-01, 1.19000000e-01, 7.23000000e-01,\n",
            "       2.60899000e+02, 1.24863000e+02, 6.37302343e-01, 5.47567024e-01]), 89: array([191.08526   ,   0.666     ,   0.296     ,   0.741     ,\n",
            "       178.26      , 134.324     ,   0.37458278,   0.41373984]), 90: array([101.642     ,   0.336     ,   0.235     ,   0.444     ,\n",
            "        96.212     , 205.702     ,   0.58234637,   0.81524626]), 91: array([2.50801180e+02, 8.60000000e-02, 1.48000000e-01, 2.57000000e-01,\n",
            "       2.40048000e+02, 1.83919000e+02, 3.83863704e-01, 4.27446571e-01]), 92: array([1.66033830e+02, 4.17000000e-01, 3.28000000e-01, 6.21000000e-01,\n",
            "       1.60061000e+02, 1.96952000e+02, 3.13044940e-01, 1.91549864e-01]), 93: array([1.76143220e+02, 1.75000000e-01, 1.19000000e-01, 3.88000000e-01,\n",
            "       1.71706000e+02, 1.36157000e+02, 4.67007123e-01, 6.00733109e-01]), 94: array([272.09098   ,   0.649     ,   0.287     ,   0.854     ,\n",
            "       272.091     , 180.568     ,   0.33633678,   0.32773668]), 95: array([3.07513020e+02, 5.06000000e-01, 2.18000000e-01, 5.94000000e-01,\n",
            "       3.03038000e+02, 1.19980000e+02, 4.44055406e-01, 5.86472505e-01]), 96: array([1.76979140e+02, 8.40000000e-02, 2.00000000e-01, 2.79000000e-01,\n",
            "       1.62575000e+02, 1.31435000e+02, 3.92262225e-01, 2.66955186e-01]), 97: array([2.51715460e+02, 1.46000000e-01, 2.18800000e+00, 3.86000000e-01,\n",
            "       2.45923000e+02, 1.41696000e+02, 3.69745832e-01, 3.75984302e-01]), 98: array([236.66893   ,   0.492     ,   0.418     ,   0.494     ,\n",
            "       221.309     , 140.077     ,   0.39201197,   0.28848164]), 99: array([3.60280360e+02, 4.61000000e-01, 2.70000000e-01, 4.43000000e-01,\n",
            "       3.56287000e+02, 1.35679000e+02, 4.61728918e-01, 3.04169503e-01])}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_14925/1059260028.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.filtered_df.dropna(inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WARNING] k_t parameter too large for generated representative subset. Consider using a larger dataset or reducing k_t value\n",
            "Setting k_t = 9 to match the generated number of representatives through delta-medoids\n",
            "fsf\n"
          ]
        }
      ],
      "source": [
        "model = MDP('MSD.csv', 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.5454545454545454"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "n_bins = 10\n",
        "n_features = 8\n",
        "var_param = 100\n",
        "user_reference = np.array([])\n",
        "k_s  = 10\n",
        "data = model.df_input\n",
        "\n",
        "user_samples = np.zeros((n_features * n_bins, k_s), dtype='int32')\n",
        "\n",
        "for i in range(n_features):\n",
        "    vec = np.random.randint(1, var_param, (n_bins, ))\n",
        "    vec = vec/np.sum(vec)\n",
        "    user_reference = np.append(user_reference, vec)\n",
        "    sample_bins = np.array(rand.choices(np.arange(len(vec), dtype='int32'), vec, k = k_s))\n",
        "    user_samples[i*n_bins + sample_bins, np.arange(k_s, dtype='int32')] = 1\n",
        "\n",
        "sample_index = np.arange(np.shape(data)[0], np.shape(data)[0] + k_s)\n",
        "to_append = pd.DataFrame(np.transpose(user_samples), index = sample_index)\n",
        "sample = data.copy().append(to_append)\n",
        "dists_with_samples = distlib.pdist(sample, metric='cosine')\n",
        "dists_with_samples = distlib.squareform(dists_with_samples)\n",
        "np.fill_diagonal(dists_with_samples, np.inf)\n",
        "# TODO: Select only the dists_with_samples relevant to us to select the min distance songs, use sample_index for indexing withing the square matrix. Select minimums, get indices --> done\n",
        "user_selected_songs = np.array([], dtype='int32')\n",
        "for i in sample_index:\n",
        "    min_ind = np.argmin(dists_with_samples[:sample_index[0], i])\n",
        "    user_selected_songs = np.append(user_selected_songs, min_ind)\n",
        "    dists_with_samples[min_ind, :] = np.inf #Do not allow to pick this row anymore\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([8., 8., 8., 8., 8., 8., 8., 8., 8., 8.])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_bins = 10\n",
        "n_features = 8\n",
        "var_param = 100\n",
        "user_reference = np.array([])\n",
        "k_s  = 10\n",
        "k_t = 10\n",
        "data = model.df_input\n",
        "\n",
        "user_transition_reference = np.array([])\n",
        "user_transition_samples = np.zeros((n_features * n_bins * n_bins, k_t))\n",
        "for i in range(n_features):\n",
        "    vec = np.random.randint(1, var_param, (n_bins * n_bins, ))\n",
        "    vec = vec/np.sum(vec)\n",
        "    user_transition_reference = np.append(user_transition_reference, vec)\n",
        "    sample_bins = np.array(rand.choices(np.arange(n_bins * n_bins, dtype='int32'), vec, k = k_t))\n",
        "    user_transition_samples[i*n_bins*n_bins + sample_bins, np.arange(k_t, dtype='int32')] = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crbFGO3wAKoZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class MCTS_DL:\n",
        "\n",
        "    def __init__(self, dl_model, model, args):\n",
        "        self.dl_model = dl_model\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "\n",
        "    def run(self, state):\n",
        "        root = Node(0)\n",
        "\n",
        "        # EXPAND root\n",
        "        action_probs, value = self.dl_model.predict(self.model.state_to_input(state))\n",
        "        valid_actions = self.model.get_valid_actions(state)\n",
        "        action_probs = action_probs * valid_actions  # mask invalid moves\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        root.expand(state, action_probs)\n",
        "\n",
        "        for _ in range(self.args['num_simulations']):\n",
        "            node = root\n",
        "            search_path = [node]\n",
        "\n",
        "            # SELECT\n",
        "            while node.expanded():\n",
        "                action, node = node.select_child()\n",
        "                search_path.append(node)\n",
        "\n",
        "            parent = search_path[-2]\n",
        "            state = parent.state\n",
        "            # Now we're at a leaf node and we would like to expand\n",
        "            # Players always play from their own perspective\n",
        "            next_state = self.model.get_next_state(state, action)\n",
        "            # Get the board from the perspective of the other player\n",
        "\n",
        "            # The value of the new state from the perspective of the other player\n",
        "            value = self.model.get_reward(next_state)\n",
        "            if value is None:\n",
        "                # If the game has not ended:\n",
        "                # EXPAND\n",
        "                action_probs, value = self.dl_model.predict(self.model.state_to_input(next_state))\n",
        "                valid_actions = self.model.get_valid_actions(next_state)\n",
        "                action_probs = action_probs * valid_actions  # mask invalid moves\n",
        "                action_probs /= np.sum(action_probs)\n",
        "                node.expand(next_state, action_probs)\n",
        "\n",
        "            self.backpropagate(search_path, value)\n",
        "\n",
        "        return root\n",
        "\n",
        "    def backpropagate(self, search_path, value):\n",
        "        \"\"\"\n",
        "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
        "        to the root.l\n",
        "        \"\"\"\n",
        "        for node in reversed(search_path):\n",
        "            node.value_sum += value \n",
        "            node.visit_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0v-iYHfDEIwe"
      },
      "outputs": [],
      "source": [
        "class MCTS:\n",
        "\n",
        "    def __init__(self, model, args):\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "\n",
        "    def run(self, root_state):\n",
        "        print(\"\")\n",
        "        root = Node(0)\n",
        "        # EXPAND root\n",
        "        action_probs = list(self.model.song_priors)\n",
        "        for song_id in range(self.model.n_songs):\n",
        "          if song_id in root_state:\n",
        "            action_probs[song_id] = 0\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        root.expand(root_state, action_probs)\n",
        "\n",
        "        for _ in range(self.args['num_simulations']):\n",
        "\n",
        "            node = root\n",
        "            search_path = [node]\n",
        "\n",
        "            # SELECT\n",
        "            while node.expanded():              \n",
        "                action, node = node.select_child()\n",
        "                search_path.append(node)\n",
        "            parent = search_path[-2]\n",
        "            state = parent.state\n",
        "            # # Now we're at a leaf node and we would like to expand\n",
        "            # # Players always play from their own perspective\n",
        "            # next_state, _ = self.game.get_next_state(state, action=action)\n",
        "            # # Get the board from the perspective of the other player\n",
        "            # next_state = self.game.get_canonical_board(next_state, )\n",
        "\n",
        "            # The value of the new state from the perspective of the other player\n",
        "            # value = self.game.get_reward_for_player(next_state)\n",
        "            next_state = parent.state + [action]\n",
        "            \n",
        "            value = model.MC_value(next_state)\n",
        "\n",
        "            action_probs = list(self.model.song_priors)\n",
        "            for song_id in range(self.model.n_songs):\n",
        "              if song_id in parent.state or song_id == action:\n",
        "                action_probs[song_id] = 0\n",
        "\n",
        "            node.expand(next_state, action_probs)\n",
        "        \n",
        "\n",
        "            # if value is None:\n",
        "                # If the game has not ended:\n",
        "                # EXPAND\n",
        "                # action_probs, value = model.predict(next_state)\n",
        "                # valid_moves = self.game.get_valid_moves(next_state)\n",
        "                # action_probs = action_probs * valid_moves  # mask invalid moves\n",
        "                # action_probs /= np.sum(action_probs)\n",
        "                # node.expand(next_state, action_probs)\n",
        "\n",
        "            self.backpropagate(search_path, value)\n",
        "\n",
        "        return root\n",
        "\n",
        "    def backpropagate(self, search_path, value):\n",
        "        \"\"\"\n",
        "        At the end of a simulation, we propagate the evaluation all the way up the tree\n",
        "        to the root.\n",
        "        \"\"\"\n",
        "        for node in reversed(search_path):\n",
        "            node.value_sum += value\n",
        "            node.visit_count += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhegWXk1VYXG"
      },
      "outputs": [],
      "source": [
        "def get_random_trajectory(model):\n",
        "  songs = set(model.songs)\n",
        "  state = []\n",
        "  trajectory_states = [state]\n",
        "  trajectory_actions = []\n",
        "  for i in range(playlist_length):\n",
        "    action = random.sample(songs, 1)[0]\n",
        "    state = model.get_next_state(state, action)\n",
        "    trajectory_states.append(state)\n",
        "    trajectory_actions.append(action)\n",
        "    songs.remove(action)\n",
        "  cum_rewards = model.payoff_trajectory(trajectory_states, trajectory_actions)\n",
        "  return cum_rewards\n",
        "\n",
        "def get_greedy_trajectory(model):\n",
        "  songs = set(model.songs)\n",
        "  state = []\n",
        "  trajectory_states = [state]\n",
        "  trajectory_actions = []\n",
        "  for i in range(playlist_length):\n",
        "    max_score = -np.inf\n",
        "    max_action = -1\n",
        "    for try_action in songs:\n",
        "      try_state = model.get_next_state(state, try_action)\n",
        "      try_trajectory_states = list(trajectory_states)\n",
        "      try_trajectory_actions = list(trajectory_actions)\n",
        "      try_trajectory_states.append(try_state)\n",
        "      try_trajectory_actions.append(try_action)\n",
        "      score = model.payoff_trajectory(try_trajectory_states, try_trajectory_actions)\n",
        "      if score > max_score:\n",
        "        max_action = try_action\n",
        "        max_score = score\n",
        "    \n",
        "    action = max_action\n",
        "    state = model.get_next_state(state, action)\n",
        "    trajectory_states.append(state)\n",
        "    trajectory_actions.append(action)\n",
        "    songs.remove(action)\n",
        "  cum_rewards = model.payoff_trajectory(trajectory_states, trajectory_actions)\n",
        "  return cum_rewards\n",
        "\n",
        "def get_MCTS_trajectory(model):\n",
        "  # MCTS\n",
        "  mcts = MCTS(model, args)\n",
        "  trajectory_states = [[]]\n",
        "  trajectory_actions = []\n",
        "  state = []\n",
        "  for i in range(playlist_length):\n",
        "    root = mcts.run(state)\n",
        "    counts = [node.visit_count for node in root.children.values()]\n",
        "    max_val = max(counts)\n",
        "    song = counts.index(max_val)\n",
        "    state = list(root.children.values())[song].state\n",
        "    trajectory_states.append(state)\n",
        "    trajectory_actions.append(song)\n",
        "    # print(counts, max_index, state)\n",
        "    for action, child in root.children.items():\n",
        "      score = ucb_score(root, child)\n",
        "      # print(child.state, score)\n",
        "  cum_rewards =  model.payoff_trajectory(trajectory_states, trajectory_actions)\n",
        "  return cum_rewards\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constants\n",
        "playlist_length = 10\n",
        "args = {\n",
        "    'batch_size': 16,\n",
        "    'numIters': 500,                                # Total number of training iterations\n",
        "    'num_simulations': 50,                         # Total number of MCTS simulations to run when deciding on a move to play\n",
        "    'numEps': 4,                                  # Number of full games (episodes) to run during each iteration\n",
        "    'numItersForTrainExamplesHistory': 20,\n",
        "    'epochs': 2,                                    # Number of epochs of training per iteration\n",
        "    'checkpoint_path': 'latest.pth'                 # location to save latest set of weights\n",
        "}\n",
        "\n",
        "model = MDP('MSD_lite.csv', playlist_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FoRL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
